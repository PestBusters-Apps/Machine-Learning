{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JlNn0gfZ3VPi",
    "outputId": "2ef7241f-09be-49dc-e389-0ec1b4b3ff53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'models'...\n",
      "remote: Enumerating objects: 4305, done.\u001b[K\n",
      "remote: Counting objects: 100% (4305/4305), done.\u001b[K\n",
      "remote: Compressing objects: 100% (3292/3292), done.\u001b[K\n",
      "remote: Total 4305 (delta 1209), reused 2191 (delta 940), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (4305/4305), 53.17 MiB | 9.42 MiB/s, done.\n",
      "Resolving deltas: 100% (1209/1209), done.\n",
      "Updating files: 100% (3875/3875), done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "# Clone model TFOD \n",
    "if \"models\" in pathlib.Path.cwd().parts:\n",
    "  while \"models\" in pathlib.Path.cwd().parts:\n",
    "    os.chdir('..')\n",
    "elif not pathlib.Path('models').exists():\n",
    "  !git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n2d3eKLW3bzm",
    "outputId": "024b54be-f062-4fa1-a5dd-6015d1be6712"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /content/models/research\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: avro-python3 in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (1.10.2)\n",
      "Requirement already satisfied: apache-beam in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.60.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (11.0.0)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (5.3.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (3.8.0)\n",
      "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (3.0.11)\n",
      "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (21.6.0)\n",
      "Requirement already satisfied: tf-slim in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (1.16.0)\n",
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.0.8)\n",
      "Requirement already satisfied: lvis in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (0.5.3)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (1.13.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.2.2)\n",
      "Requirement already satisfied: tf-models-official>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.18.0)\n",
      "Requirement already satisfied: tensorflow_io in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (0.37.1)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.11.0)\n",
      "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.4.7)\n",
      "Requirement already satisfied: sacrebleu<=2.2.0 in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.2.0)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (2.10.1)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (2024.9.11)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (1.26.4)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.4.6)\n",
      "Requirement already satisfied: ai-edge-litert>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (1.0.1)\n",
      "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.5.0)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.151.0)\n",
      "Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.2.0)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (1.6.17)\n",
      "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.1.3)\n",
      "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.10.0.84)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (9.0.0)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (6.0.2)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.2.0)\n",
      "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (1.2.2)\n",
      "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.9.7)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.16.1)\n",
      "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.8.0)\n",
      "Requirement already satisfied: tensorflow-text~=2.18.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.18.0)\n",
      "Collecting tensorflow~=2.18.0 (from tf-models-official>=2.5.1->object_detection==0.1)\n",
      "  Using cached tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tf-keras>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.18.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->object_detection==0.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object_detection==0.1) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->object_detection==0.1) (2024.2)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf-slim->object_detection==0.1) (1.4.0)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (1.7)\n",
      "Requirement already satisfied: orjson<4,>=3.9.7 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (3.10.11)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (0.3.1.1)\n",
      "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (2.2.1)\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (1.9.7)\n",
      "Requirement already satisfied: fasteners<1.0,>=0.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (0.19)\n",
      "Requirement already satisfied: grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (1.65.5)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (2.7.3)\n",
      "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (0.22.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (4.23.0)\n",
      "Requirement already satisfied: jsonpickle<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (3.4.2)\n",
      "Requirement already satisfied: objsize<0.8.0,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (0.7.0)\n",
      "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (24.2)\n",
      "Requirement already satisfied: pymongo<5.0.0,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (4.10.1)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (1.25.0)\n",
      "Collecting protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<4.26.0,>=3.20.3 (from apache-beam->object_detection==0.1)\n",
      "  Downloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (1.4.2)\n",
      "Requirement already satisfied: redis<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (5.2.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (4.12.2)\n",
      "Requirement already satisfied: zstandard<1,>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (0.23.0)\n",
      "Requirement already satisfied: pyarrow<17.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix<1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (0.6)\n",
      "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object_detection==0.1) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object_detection==0.1) (1.4.7)\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from lvis->object_detection==0.1) (4.10.0.84)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object_detection==0.1) (1.3.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object_detection==0.1) (4.54.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.37.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_io->object_detection==0.1) (0.37.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (2.27.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (2.19.2)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (4.1.1)\n",
      "Requirement already satisfied: docopt in /usr/local/lib/python3.10/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object_detection==0.1) (0.6.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.21.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (2024.8.30)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (4.66.6)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (2.2.3)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (6.2.0)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo<5.0.0,>=3.8.0->apache-beam->object_detection==0.1) (2.7.0)\n",
      "Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis<6,>=5.0.0->apache-beam->object_detection==0.1) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object_detection==0.1) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object_detection==0.1) (3.10)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.18.0->tf-models-official>=2.5.1->object_detection==0.1) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.18.0->tf-models-official>=2.5.1->object_detection==0.1) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.18.0->tf-models-official>=2.5.1->object_detection==0.1) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.18.0->tf-models-official>=2.5.1->object_detection==0.1) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.18.0->tf-models-official>=2.5.1->object_detection==0.1) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.18.0->tf-models-official>=2.5.1->object_detection==0.1) (3.4.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.18.0->tf-models-official>=2.5.1->object_detection==0.1) (75.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.18.0->tf-models-official>=2.5.1->object_detection==0.1) (2.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.18.0->tf-models-official>=2.5.1->object_detection==0.1) (1.16.0)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow~=2.18.0->tf-models-official>=2.5.1->object_detection==0.1)\n",
      "  Using cached tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras (from object_detection==0.1)\n",
      "  Using cached keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.18.0->tf-models-official>=2.5.1->object_detection==0.1) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.18.0->tf-models-official>=2.5.1->object_detection==0.1) (0.4.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->object_detection==0.1) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->object_detection==0.1) (0.0.8)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->object_detection==0.1) (0.13.0)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object_detection==0.1) (0.1.8)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (0.6.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (0.4.1)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (4.9)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->object_detection==0.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->object_detection==0.1) (2.18.0)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official>=2.5.1->object_detection==0.1) (1.5.2)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (8.1.7)\n",
      "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (2.3)\n",
      "Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.1.6)\n",
      "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (1.13.1)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.10.2)\n",
      "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.5.1)\n",
      "Requirement already satisfied: etils>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (1.10.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.18.0->tf-models-official>=2.5.1->object_detection==0.1) (0.44.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (2024.10.0)\n",
      "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (6.4.5)\n",
      "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (3.20.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (1.65.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (5.5.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->object_detection==0.1) (0.1.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object_detection==0.1) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object_detection==0.1) (3.5.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow~=2.18.0->tf-models-official>=2.5.1->object_detection==0.1) (3.7)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow~=2.18.0->tf-models-official>=2.5.1->object_detection==0.1)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow~=2.18.0->tf-models-official>=2.5.1->object_detection==0.1) (3.1.3)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (1.3)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.16)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow~=2.18.0->tf-models-official>=2.5.1->object_detection==0.1) (3.0.2)\n",
      "Downloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 294.6/294.6 kB 7.1 MB/s eta 0:00:00\n",
      "Using cached tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.3 MB)\n",
      "Using cached keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 10.5 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: object_detection\n",
      "  Building wheel for object_detection (setup.py): started\n",
      "  Building wheel for object_detection (setup.py): finished with status 'done'\n",
      "  Created wheel for object_detection: filename=object_detection-0.1-py3-none-any.whl size=1697357 sha256=5a46a065548d884c333636d4dbe87f8e2b2057447f71abd7cf6a8566fb39109c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-9yrqhbzd/wheels/53/dd/70/2de274d6c443c69d367bd6a5606f95e5a6df61aacf1435ec0d\n",
      "Successfully built object_detection\n",
      "Installing collected packages: tensorboard-data-server, protobuf, tensorboard, keras, tensorflow, object_detection\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.6.1\n",
      "    Uninstalling tensorboard-data-server-0.6.1:\n",
      "      Successfully uninstalled tensorboard-data-server-0.6.1\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.11.2\n",
      "    Uninstalling tensorboard-2.11.2:\n",
      "      Successfully uninstalled tensorboard-2.11.2\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.11.0\n",
      "    Uninstalling keras-2.11.0:\n",
      "      Successfully uninstalled keras-2.11.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.11.0\n",
      "    Uninstalling tensorflow-2.11.0:\n",
      "      Successfully uninstalled tensorflow-2.11.0\n",
      "  Attempting uninstall: object_detection\n",
      "    Found existing installation: object_detection 0.1\n",
      "    Uninstalling object_detection-0.1:\n",
      "      Successfully uninstalled object_detection-0.1\n",
      "Successfully installed keras-3.6.0 object_detection-0.1 protobuf-4.25.5 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pandas-gbq 0.24.0 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd models/research/\n",
    "protoc object_detection/protos/*.proto --python_out=.\n",
    "cp object_detection/packages/tf2/setup.py .\n",
    "python -m pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bSPj1IIffm7U",
    "outputId": "970ce9af-ffb2-4b54-c433-a00e61ce6021"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.14.0 (from tensorflow[and-cuda]==2.14.0)\n",
      "  Downloading tensorflow-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (18.1.1)\n",
      "Collecting ml-dtypes==0.2.0 (from tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0)\n",
      "  Downloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (4.25.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (4.5.0)\n",
      "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0)\n",
      "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (0.37.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (1.65.5)\n",
      "Collecting tensorboard<2.15,>=2.14 (from tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0)\n",
      "  Downloading tensorboard-2.14.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0)\n",
      "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.15,>=2.14.0 (from tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0)\n",
      "  Downloading keras-2.14.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.8.89 (from tensorflow[and-cuda]==2.14.0)\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cublas-cu11==11.11.3.6 (from tensorflow[and-cuda]==2.14.0)\n",
      "  Downloading nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58 (from tensorflow[and-cuda]==2.14.0)\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cudnn-cu11==8.7.0.84 (from tensorflow[and-cuda]==2.14.0)\n",
      "  Downloading nvidia_cudnn_cu11-8.7.0.84-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-curand-cu11==10.3.0.86 (from tensorflow[and-cuda]==2.14.0)\n",
      "  Downloading nvidia_curand_cu11-10.3.0.86-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.1.48 (from tensorflow[and-cuda]==2.14.0)\n",
      "  Downloading nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.5.86 (from tensorflow[and-cuda]==2.14.0)\n",
      "  Downloading nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-nccl-cu11==2.16.5 (from tensorflow[and-cuda]==2.14.0)\n",
      "  Downloading nvidia_nccl_cu11-2.16.5-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.8.87 (from tensorflow[and-cuda]==2.14.0)\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-nvcc-cu11==11.8.89 (from tensorflow[and-cuda]==2.14.0)\n",
      "  Downloading nvidia_cuda_nvcc_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting tensorrt==8.5.3.1 (from tensorflow[and-cuda]==2.14.0)\n",
      "  Downloading tensorrt-8.5.3.1-cp310-none-manylinux_2_17_x86_64.whl.metadata (721 bytes)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (0.44.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (3.1.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (3.0.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0->tensorflow[and-cuda]==2.14.0) (3.2.2)\n",
      "Downloading tensorflow-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.8/489.8 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux2014_x86_64.whl (417.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvcc_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl (19.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl (875 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu11-8.7.0.84-py3-none-manylinux1_x86_64.whl (728.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m728.5/728.5 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu11-10.3.0.86-py3-none-manylinux2014_x86_64.whl (58.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux2014_x86_64.whl (128.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux2014_x86_64.whl (204.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu11-2.16.5-py3-none-manylinux1_x86_64.whl (210.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.3/210.3 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorrt-8.5.3.1-cp310-none-manylinux_2_17_x86_64.whl (549.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.5/549.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvcc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, ml-dtypes, keras, nvidia-cusolver-cu11, nvidia-cudnn-cu11, tensorrt, tensorboard, tensorflow\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.16.0\n",
      "    Uninstalling wrapt-1.16.0:\n",
      "      Successfully uninstalled wrapt-1.16.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.13.0\n",
      "    Uninstalling tensorflow-estimator-2.13.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.13.0\n",
      "  Attempting uninstall: ml-dtypes\n",
      "    Found existing installation: ml-dtypes 0.4.1\n",
      "    Uninstalling ml-dtypes-0.4.1:\n",
      "      Successfully uninstalled ml-dtypes-0.4.1\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.13.1\n",
      "    Uninstalling keras-2.13.1:\n",
      "      Successfully uninstalled keras-2.13.1\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.13.0\n",
      "    Uninstalling tensorboard-2.13.0:\n",
      "      Successfully uninstalled tensorboard-2.13.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.13.0\n",
      "    Uninstalling tensorflow-2.13.0:\n",
      "      Successfully uninstalled tensorflow-2.13.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-text 2.18.0 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.14.0 which is incompatible.\n",
      "tensorstore 0.1.67 requires ml-dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
      "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.14.0 which is incompatible.\n",
      "tf-models-official 2.18.0 requires tensorflow~=2.18.0, but you have tensorflow 2.14.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed keras-2.14.0 ml-dtypes-0.2.0 nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvcc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-8.7.0.84 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.16.5 tensorboard-2.14.1 tensorflow-2.14.0 tensorflow-estimator-2.14.0 tensorrt-8.5.3.1 wrapt-1.14.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "4b465c6174ea4bebb9c8c4b7641b51d2",
       "pip_warning": {
        "packages": [
         "keras",
         "ml_dtypes",
         "tensorboard",
         "tensorflow",
         "wrapt"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install tensorflow==2.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VvItYCfl3goE"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "import io\n",
    "import imageio\n",
    "import glob\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from six import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display, Javascript\n",
    "from IPython.display import Image as IPyImage\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.utils import colab_utils\n",
    "from object_detection.builders import model_builder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Menjalankan model builder test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0wr2hRN33hCe",
    "outputId": "5fccb1f4-cafb-4068-fb7e-922e18a5a65a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-13 12:33:38.002502: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-13 12:33:38.002563: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-13 12:33:38.002613: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Running tests under Python 3.10.12: /usr/bin/python3\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "2024-11-13 12:33:42.614878: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n",
      "W1113 12:33:42.661568 136252382716544 batch_normalization.py:1531] `tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n",
      "W1113 12:33:43.128960 136252382716544 model_builder.py:1112] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.18s\n",
      "I1113 12:33:43.625246 136252382716544 test_util.py:2472] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.18s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.93s\n",
      "I1113 12:33:44.552437 136252382716544 test_util.py:2472] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.93s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.51s\n",
      "I1113 12:33:45.064973 136252382716544 test_util.py:2472] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.51s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.3s\n",
      "I1113 12:33:45.368183 136252382716544 test_util.py:2472] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.3s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.98s\n",
      "I1113 12:33:48.349897 136252382716544 test_util.py:2472] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.98s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "I1113 12:33:48.359370 136252382716544 test_util.py:2472] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n",
      "I1113 12:33:48.401618 136252382716544 test_util.py:2472] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.03s\n",
      "I1113 12:33:48.431813 136252382716544 test_util.py:2472] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.03s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.03s\n",
      "I1113 12:33:48.465753 136252382716544 test_util.py:2472] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.03s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.19s\n",
      "I1113 12:33:48.653994 136252382716544 test_util.py:2472] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.19s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.18s\n",
      "I1113 12:33:48.833367 136252382716544 test_util.py:2472] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.18s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.19s\n",
      "I1113 12:33:49.020574 136252382716544 test_util.py:2472] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.19s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.18s\n",
      "I1113 12:33:49.200122 136252382716544 test_util.py:2472] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.18s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.2s\n",
      "I1113 12:33:49.397967 136252382716544 test_util.py:2472] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.2s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.05s\n",
      "I1113 12:33:49.450836 136252382716544 test_util.py:2472] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.05s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "I1113 12:33:49.807250 136252382716544 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I1113 12:33:49.807463 136252382716544 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 64\n",
      "I1113 12:33:49.807551 136252382716544 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 3\n",
      "I1113 12:33:49.816542 136252382716544 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I1113 12:33:49.861438 136252382716544 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I1113 12:33:49.861598 136252382716544 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I1113 12:33:49.980059 136252382716544 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I1113 12:33:49.980276 136252382716544 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I1113 12:33:50.300026 136252382716544 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I1113 12:33:50.300224 136252382716544 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I1113 12:33:50.606696 136252382716544 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I1113 12:33:50.606861 136252382716544 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I1113 12:33:50.914509 136252382716544 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I1113 12:33:50.914673 136252382716544 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I1113 12:33:51.209702 136252382716544 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I1113 12:33:51.209859 136252382716544 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I1113 12:33:51.601838 136252382716544 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I1113 12:33:51.602006 136252382716544 efficientnet_model.py:143] round_filter input=320 output=320\n",
      "I1113 12:33:51.699595 136252382716544 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
      "I1113 12:33:51.746113 136252382716544 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1113 12:33:52.023169 136252382716544 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
      "I1113 12:33:52.023344 136252382716544 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88\n",
      "I1113 12:33:52.023418 136252382716544 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4\n",
      "I1113 12:33:52.025401 136252382716544 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I1113 12:33:52.044560 136252382716544 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I1113 12:33:52.044661 136252382716544 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I1113 12:33:52.199938 136252382716544 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I1113 12:33:52.200076 136252382716544 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I1113 12:33:52.484701 136252382716544 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I1113 12:33:52.484854 136252382716544 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I1113 12:33:52.769551 136252382716544 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I1113 12:33:52.769703 136252382716544 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I1113 12:33:53.172175 136252382716544 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I1113 12:33:53.172368 136252382716544 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I1113 12:33:53.570177 136252382716544 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I1113 12:33:53.570378 136252382716544 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I1113 12:33:54.044974 136252382716544 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I1113 12:33:54.045146 136252382716544 efficientnet_model.py:143] round_filter input=320 output=320\n",
      "I1113 12:33:54.249250 136252382716544 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
      "I1113 12:33:54.283787 136252382716544 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1113 12:33:54.349429 136252382716544 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
      "I1113 12:33:54.349578 136252382716544 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 112\n",
      "I1113 12:33:54.349647 136252382716544 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 5\n",
      "I1113 12:33:54.351707 136252382716544 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I1113 12:33:54.370350 136252382716544 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I1113 12:33:54.370456 136252382716544 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I1113 12:33:54.533914 136252382716544 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I1113 12:33:54.534066 136252382716544 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I1113 12:33:54.813964 136252382716544 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I1113 12:33:54.814127 136252382716544 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I1113 12:33:55.105481 136252382716544 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I1113 12:33:55.105654 136252382716544 efficientnet_model.py:143] round_filter input=80 output=88\n",
      "I1113 12:33:55.502423 136252382716544 efficientnet_model.py:143] round_filter input=80 output=88\n",
      "I1113 12:33:55.502586 136252382716544 efficientnet_model.py:143] round_filter input=112 output=120\n",
      "I1113 12:33:55.911813 136252382716544 efficientnet_model.py:143] round_filter input=112 output=120\n",
      "I1113 12:33:55.911987 136252382716544 efficientnet_model.py:143] round_filter input=192 output=208\n",
      "I1113 12:33:56.403785 136252382716544 efficientnet_model.py:143] round_filter input=192 output=208\n",
      "I1113 12:33:56.403960 136252382716544 efficientnet_model.py:143] round_filter input=320 output=352\n",
      "I1113 12:33:56.611947 136252382716544 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
      "I1113 12:33:56.652417 136252382716544 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1113 12:33:56.722961 136252382716544 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
      "I1113 12:33:56.723123 136252382716544 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 160\n",
      "I1113 12:33:56.723196 136252382716544 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 6\n",
      "I1113 12:33:56.725465 136252382716544 efficientnet_model.py:143] round_filter input=32 output=40\n",
      "I1113 12:33:56.746520 136252382716544 efficientnet_model.py:143] round_filter input=32 output=40\n",
      "I1113 12:33:56.746667 136252382716544 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I1113 12:33:56.906325 136252382716544 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I1113 12:33:56.906481 136252382716544 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I1113 12:33:57.193931 136252382716544 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I1113 12:33:57.194102 136252382716544 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I1113 12:33:57.616114 136252382716544 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I1113 12:33:57.616360 136252382716544 efficientnet_model.py:143] round_filter input=80 output=96\n",
      "I1113 12:33:58.242234 136252382716544 efficientnet_model.py:143] round_filter input=80 output=96\n",
      "I1113 12:33:58.242420 136252382716544 efficientnet_model.py:143] round_filter input=112 output=136\n",
      "I1113 12:33:58.736722 136252382716544 efficientnet_model.py:143] round_filter input=112 output=136\n",
      "I1113 12:33:58.736909 136252382716544 efficientnet_model.py:143] round_filter input=192 output=232\n",
      "I1113 12:33:59.357725 136252382716544 efficientnet_model.py:143] round_filter input=192 output=232\n",
      "I1113 12:33:59.357892 136252382716544 efficientnet_model.py:143] round_filter input=320 output=384\n",
      "I1113 12:33:59.565114 136252382716544 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
      "I1113 12:33:59.609008 136252382716544 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1113 12:33:59.689604 136252382716544 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
      "I1113 12:33:59.689749 136252382716544 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 224\n",
      "I1113 12:33:59.689821 136252382716544 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n",
      "I1113 12:33:59.691728 136252382716544 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I1113 12:33:59.711389 136252382716544 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I1113 12:33:59.711497 136252382716544 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I1113 12:33:59.884730 136252382716544 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I1113 12:33:59.884897 136252382716544 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I1113 12:34:00.282515 136252382716544 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I1113 12:34:00.282691 136252382716544 efficientnet_model.py:143] round_filter input=40 output=56\n",
      "I1113 12:34:01.099569 136252382716544 efficientnet_model.py:143] round_filter input=40 output=56\n",
      "I1113 12:34:01.099769 136252382716544 efficientnet_model.py:143] round_filter input=80 output=112\n",
      "I1113 12:34:01.897583 136252382716544 efficientnet_model.py:143] round_filter input=80 output=112\n",
      "I1113 12:34:01.897797 136252382716544 efficientnet_model.py:143] round_filter input=112 output=160\n",
      "I1113 12:34:02.761008 136252382716544 efficientnet_model.py:143] round_filter input=112 output=160\n",
      "I1113 12:34:02.761237 136252382716544 efficientnet_model.py:143] round_filter input=192 output=272\n",
      "I1113 12:34:03.914295 136252382716544 efficientnet_model.py:143] round_filter input=192 output=272\n",
      "I1113 12:34:03.914554 136252382716544 efficientnet_model.py:143] round_filter input=320 output=448\n",
      "I1113 12:34:04.218320 136252382716544 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
      "I1113 12:34:04.276196 136252382716544 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1113 12:34:04.419083 136252382716544 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
      "I1113 12:34:04.419253 136252382716544 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 288\n",
      "I1113 12:34:04.419344 136252382716544 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n",
      "I1113 12:34:04.422295 136252382716544 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I1113 12:34:04.447365 136252382716544 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I1113 12:34:04.447572 136252382716544 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I1113 12:34:04.758270 136252382716544 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I1113 12:34:04.758456 136252382716544 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I1113 12:34:05.230375 136252382716544 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I1113 12:34:05.230554 136252382716544 efficientnet_model.py:143] round_filter input=40 output=64\n",
      "I1113 12:34:05.719640 136252382716544 efficientnet_model.py:143] round_filter input=40 output=64\n",
      "I1113 12:34:05.719799 136252382716544 efficientnet_model.py:143] round_filter input=80 output=128\n",
      "I1113 12:34:06.389753 136252382716544 efficientnet_model.py:143] round_filter input=80 output=128\n",
      "I1113 12:34:06.389912 136252382716544 efficientnet_model.py:143] round_filter input=112 output=176\n",
      "I1113 12:34:07.079761 136252382716544 efficientnet_model.py:143] round_filter input=112 output=176\n",
      "I1113 12:34:07.079935 136252382716544 efficientnet_model.py:143] round_filter input=192 output=304\n",
      "I1113 12:34:07.959651 136252382716544 efficientnet_model.py:143] round_filter input=192 output=304\n",
      "I1113 12:34:07.959830 136252382716544 efficientnet_model.py:143] round_filter input=320 output=512\n",
      "I1113 12:34:08.276499 136252382716544 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
      "I1113 12:34:08.317252 136252382716544 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1113 12:34:08.409698 136252382716544 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
      "I1113 12:34:08.409832 136252382716544 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n",
      "I1113 12:34:08.409896 136252382716544 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n",
      "I1113 12:34:08.411822 136252382716544 efficientnet_model.py:143] round_filter input=32 output=56\n",
      "I1113 12:34:08.430889 136252382716544 efficientnet_model.py:143] round_filter input=32 output=56\n",
      "I1113 12:34:08.430995 136252382716544 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I1113 12:34:08.665060 136252382716544 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I1113 12:34:08.665207 136252382716544 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I1113 12:34:09.240428 136252382716544 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I1113 12:34:09.240591 136252382716544 efficientnet_model.py:143] round_filter input=40 output=72\n",
      "I1113 12:34:09.819155 136252382716544 efficientnet_model.py:143] round_filter input=40 output=72\n",
      "I1113 12:34:09.819342 136252382716544 efficientnet_model.py:143] round_filter input=80 output=144\n",
      "I1113 12:34:10.664998 136252382716544 efficientnet_model.py:143] round_filter input=80 output=144\n",
      "I1113 12:34:10.665171 136252382716544 efficientnet_model.py:143] round_filter input=112 output=200\n",
      "I1113 12:34:11.778964 136252382716544 efficientnet_model.py:143] round_filter input=112 output=200\n",
      "I1113 12:34:11.779170 136252382716544 efficientnet_model.py:143] round_filter input=192 output=344\n",
      "I1113 12:34:12.869868 136252382716544 efficientnet_model.py:143] round_filter input=192 output=344\n",
      "I1113 12:34:12.870047 136252382716544 efficientnet_model.py:143] round_filter input=320 output=576\n",
      "I1113 12:34:13.168217 136252382716544 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
      "I1113 12:34:13.215751 136252382716544 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1113 12:34:13.321703 136252382716544 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
      "I1113 12:34:13.321851 136252382716544 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n",
      "I1113 12:34:13.321927 136252382716544 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n",
      "I1113 12:34:13.324120 136252382716544 efficientnet_model.py:143] round_filter input=32 output=64\n",
      "I1113 12:34:13.344328 136252382716544 efficientnet_model.py:143] round_filter input=32 output=64\n",
      "I1113 12:34:13.344452 136252382716544 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I1113 12:34:13.654612 136252382716544 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I1113 12:34:13.654775 136252382716544 efficientnet_model.py:143] round_filter input=24 output=48\n",
      "I1113 12:34:14.333979 136252382716544 efficientnet_model.py:143] round_filter input=24 output=48\n",
      "I1113 12:34:14.334152 136252382716544 efficientnet_model.py:143] round_filter input=40 output=80\n",
      "I1113 12:34:15.157108 136252382716544 efficientnet_model.py:143] round_filter input=40 output=80\n",
      "I1113 12:34:15.157305 136252382716544 efficientnet_model.py:143] round_filter input=80 output=160\n",
      "I1113 12:34:16.462233 136252382716544 efficientnet_model.py:143] round_filter input=80 output=160\n",
      "I1113 12:34:16.462482 136252382716544 efficientnet_model.py:143] round_filter input=112 output=224\n",
      "I1113 12:34:17.851607 136252382716544 efficientnet_model.py:143] round_filter input=112 output=224\n",
      "I1113 12:34:17.851845 136252382716544 efficientnet_model.py:143] round_filter input=192 output=384\n",
      "I1113 12:34:19.448147 136252382716544 efficientnet_model.py:143] round_filter input=192 output=384\n",
      "I1113 12:34:19.448314 136252382716544 efficientnet_model.py:143] round_filter input=320 output=640\n",
      "I1113 12:34:19.861023 136252382716544 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
      "I1113 12:34:19.898318 136252382716544 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 30.57s\n",
      "I1113 12:34:20.020178 136252382716544 test_util.py:2472] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 30.57s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "I1113 12:34:20.054171 136252382716544 test_util.py:2472] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "I1113 12:34:20.055875 136252382716544 test_util.py:2472] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "I1113 12:34:20.056409 136252382716544 test_util.py:2472] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "I1113 12:34:20.057848 136252382716544 test_util.py:2472] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTF2Test.test_session\n",
      "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "I1113 12:34:20.059176 136252382716544 test_util.py:2472] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "I1113 12:34:20.059609 136252382716544 test_util.py:2472] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "I1113 12:34:20.060580 136252382716544 test_util.py:2472] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 24 tests in 37.612s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memuat gambar dari file ke dalam numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tKo2XEJK3i5N"
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(path):\n",
    "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
    "  image = Image.open(BytesIO(img_data))\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "def plot_detections(image_np,\n",
    "                    boxes,\n",
    "                    classes,\n",
    "                    scores,\n",
    "                    category_index,\n",
    "                    figsize=(12, 16),\n",
    "                    image_name=None):\n",
    "  \n",
    "  image_np_with_annotations = image_np.copy()\n",
    "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np_with_annotations,\n",
    "      boxes,\n",
    "      classes,\n",
    "      scores,\n",
    "      category_index,\n",
    "      use_normalized_coordinates=True,\n",
    "      min_score_thresh=0.8)\n",
    "  if image_name:\n",
    "    plt.imsave(image_name, image_np_with_annotations)\n",
    "  else:\n",
    "    plt.imshow(image_np_with_annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ambil gambar pada Dataset yang ada di Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ojYenpng3lu2",
    "outputId": "fda3d481-e142-4947-8661-be7c9c9b5228"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: roboflow in /usr/local/lib/python3.10/dist-packages (1.1.49)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2024.8.30)\n",
      "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7)\n",
      "Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.7)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.24.3)\n",
      "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (11.0.0)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.32.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.6)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.2)\n",
      "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.3.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.54.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (2.4.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.4.0)\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"Agk88hbUOjF1YUs8mxWw\", model_format=\"tfrecord\", notebook=\"roboflow-tf2-od\")\n",
    "project = rf.workspace(\"capstone-x2wm7\").project(\"hama-tanaman-berdaun-cy6p5\")\n",
    "version = project.version(3)\n",
    "dataset = version.download(\"tfrecord\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v435-Nf64JeZ"
   },
   "outputs": [],
   "source": [
    "test_record_fname = dataset.location + '/test/Hama.tfrecord'\n",
    "train_record_fname = dataset.location + '/train/Hama.tfrecord'\n",
    "label_map_pbtxt_fname = dataset.location + '/train/Hama_label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Membuat Pilihan Model TFOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v9NBvNM45wmc"
   },
   "outputs": [],
   "source": [
    "MODELS_CONFIG = {\n",
    "    'efficientdet-d0': {\n",
    "        'model_name': 'efficientdet_d0_coco17_tpu-32',\n",
    "        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n",
    "        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n",
    "        'batch_size': 16\n",
    "    },\n",
    "    'efficientdet-d1': {\n",
    "        'model_name': 'efficientdet_d1_coco17_tpu-32',\n",
    "        'base_pipeline_file': 'ssd_efficientdet_d1_640x640_coco17_tpu-8.config',\n",
    "        'pretrained_checkpoint': 'efficientdet_d1_coco17_tpu-32.tar.gz',\n",
    "        'batch_size': 16\n",
    "    },\n",
    "    'efficientdet-d2': {\n",
    "        'model_name': 'efficientdet_d2_coco17_tpu-32',\n",
    "        'base_pipeline_file': 'ssd_efficientdet_d2_768x768_coco17_tpu-8.config',\n",
    "        'pretrained_checkpoint': 'efficientdet_d2_coco17_tpu-32.tar.gz',\n",
    "        'batch_size': 16\n",
    "    },\n",
    "        'efficientdet-d3': {\n",
    "        'model_name': 'efficientdet_d3_coco17_tpu-32',\n",
    "        'base_pipeline_file': 'ssd_efficientdet_d3_896x896_coco17_tpu-32.config',\n",
    "        'pretrained_checkpoint': 'efficientdet_d3_coco17_tpu-32.tar.gz',\n",
    "        'batch_size': 16\n",
    "    }\n",
    "}\n",
    "chosen_model = 'efficientdet-d0'\n",
    "\n",
    "num_steps = 50000\n",
    "num_eval_steps = 500\n",
    "\n",
    "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
    "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
    "base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']\n",
    "batch_size = MODELS_CONFIG[chosen_model]['batch_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aVYZ4nB15zuf",
    "outputId": "9f945c47-9a3f-4f0e-d26b-bfa970576531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/content/models/research/deploy/’: File exists\n",
      "/content/models/research/deploy\n",
      "--2024-11-13 12:38:39--  http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.137.207, 142.250.101.207, 142.251.2.207, ...\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.137.207|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 30736482 (29M) [application/x-tar]\n",
      "Saving to: ‘efficientdet_d0_coco17_tpu-32.tar.gz.1’\n",
      "\n",
      "efficientdet_d0_coc 100%[===================>]  29.31M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2024-11-13 12:38:40 (218 MB/s) - ‘efficientdet_d0_coco17_tpu-32.tar.gz.1’ saved [30736482/30736482]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%mkdir /content/models/research/deploy/\n",
    "%cd /content/models/research/deploy/\n",
    "import tarfile\n",
    "download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n",
    "\n",
    "!wget {download_tar}\n",
    "tar = tarfile.open(pretrained_checkpoint)\n",
    "tar.extractall()\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download base training configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-BiiQvAN52T6",
    "outputId": "533956c8-0c22-4363-fde4-ce657c37a289"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/models/research/deploy\n",
      "--2024-11-13 12:38:40--  https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_efficientdet_d0_512x512_coco17_tpu-8.config\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4630 (4.5K) [text/plain]\n",
      "Saving to: ‘ssd_efficientdet_d0_512x512_coco17_tpu-8.config.1’\n",
      "\n",
      "\r          ssd_effic   0%[                    ]       0  --.-KB/s               \rssd_efficientdet_d0 100%[===================>]   4.52K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-11-13 12:38:40 (47.6 MB/s) - ‘ssd_efficientdet_d0_512x512_coco17_tpu-8.config.1’ saved [4630/4630]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%cd /content/models/research/deploy\n",
    "download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n",
    "!wget {download_config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aNVTYJmt55sl"
   },
   "outputs": [],
   "source": [
    "pipeline_fname = '/content/models/research/deploy/' + base_pipeline_file\n",
    "fine_tune_checkpoint = '/content/models/research/deploy/' + model_name + '/checkpoint/ckpt-0'\n",
    "\n",
    "def get_num_classes(pbtxt_fname):\n",
    "    from object_detection.utils import label_map_util\n",
    "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
    "    categories = label_map_util.convert_label_map_to_categories(\n",
    "        label_map, max_num_classes=90, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "    return len(category_index.keys())\n",
    "num_classes = get_num_classes(label_map_pbtxt_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Menulis file konfigurasi khusus dengan memasukkan dataset, model checkpoint, dan parameter pelatihan ke dalam file pipeline dasar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vE2DOfVp5_LA",
    "outputId": "68cc8d8f-9b2a-4d4f-dd02-a5108afedca9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/models/research/deploy\n",
      "writing custom configuration file\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "%cd /content/models/research/deploy\n",
    "print('writing custom configuration file')\n",
    "\n",
    "with open(pipeline_fname) as f:\n",
    "    s = f.read()\n",
    "with open('pipeline_file.config', 'w') as f:\n",
    "\n",
    "    # fine_tune_checkpoint\n",
    "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
    "\n",
    "    # tfrecord files train and test.\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
    "\n",
    "    # label_map_path\n",
    "    s = re.sub(\n",
    "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
    "\n",
    "    # Set training batch_size.\n",
    "    s = re.sub('batch_size: [0-9]+',\n",
    "               'batch_size: {}'.format(batch_size), s)\n",
    "\n",
    "    # Set training steps, num_steps\n",
    "    s = re.sub('num_steps: [0-9]+',\n",
    "               'num_steps: {}'.format(num_steps), s)\n",
    "\n",
    "    # Set number of classes num_classes.\n",
    "    s = re.sub('num_classes: [0-9]+',\n",
    "               'num_classes: {}'.format(num_classes), s)\n",
    "\n",
    "    #fine-tune checkpoint type\n",
    "    s = re.sub(\n",
    "        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
    "\n",
    "    f.write(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M8knnD3U6AZZ",
    "outputId": "a301f914-359f-4d1c-c9f7-a56d095a34ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # SSD with EfficientNet-b0 + BiFPN feature extractor,\n",
      "# shared box predictor and focal loss (a.k.a EfficientDet-d0).\n",
      "# See EfficientDet, Tan et al, https://arxiv.org/abs/1911.09070\n",
      "# See Lin et al, https://arxiv.org/abs/1708.02002\n",
      "# Trained on COCO, initialized from an EfficientNet-b0 checkpoint.\n",
      "#\n",
      "# Train on TPU-8\n",
      "\n",
      "model {\n",
      "  ssd {\n",
      "    inplace_batchnorm_update: true\n",
      "    freeze_batchnorm: false\n",
      "    num_classes: 7\n",
      "    add_background_class: false\n",
      "    box_coder {\n",
      "      faster_rcnn_box_coder {\n",
      "        y_scale: 10.0\n",
      "        x_scale: 10.0\n",
      "        height_scale: 5.0\n",
      "        width_scale: 5.0\n",
      "      }\n",
      "    }\n",
      "    matcher {\n",
      "      argmax_matcher {\n",
      "        matched_threshold: 0.5\n",
      "        unmatched_threshold: 0.5\n",
      "        ignore_thresholds: false\n",
      "        negatives_lower_than_unmatched: true\n",
      "        force_match_for_each_row: true\n",
      "        use_matmul_gather: true\n",
      "      }\n",
      "    }\n",
      "    similarity_calculator {\n",
      "      iou_similarity {\n",
      "      }\n",
      "    }\n",
      "    encode_background_as_zeros: true\n",
      "    anchor_generator {\n",
      "      multiscale_anchor_generator {\n",
      "        min_level: 3\n",
      "        max_level: 7\n",
      "        anchor_scale: 4.0\n",
      "        aspect_ratios: [1.0, 2.0, 0.5]\n",
      "        scales_per_octave: 3\n",
      "      }\n",
      "    }\n",
      "    image_resizer {\n",
      "      keep_aspect_ratio_resizer {\n",
      "        min_dimension: 512\n",
      "        max_dimension: 512\n",
      "        pad_to_max_dimension: true\n",
      "        }\n",
      "    }\n",
      "    box_predictor {\n",
      "      weight_shared_convolutional_box_predictor {\n",
      "        depth: 64\n",
      "        class_prediction_bias_init: -4.6\n",
      "        conv_hyperparams {\n",
      "          force_use_bias: true\n",
      "          activation: SWISH\n",
      "          regularizer {\n",
      "            l2_regularizer {\n",
      "              weight: 0.00004\n",
      "            }\n",
      "          }\n",
      "          initializer {\n",
      "            random_normal_initializer {\n",
      "              stddev: 0.01\n",
      "              mean: 0.0\n",
      "            }\n",
      "          }\n",
      "          batch_norm {\n",
      "            scale: true\n",
      "            decay: 0.99\n",
      "            epsilon: 0.001\n",
      "          }\n",
      "        }\n",
      "        num_layers_before_predictor: 3\n",
      "        kernel_size: 3\n",
      "        use_depthwise: true\n",
      "      }\n",
      "    }\n",
      "    feature_extractor {\n",
      "      type: 'ssd_efficientnet-b0_bifpn_keras'\n",
      "      bifpn {\n",
      "        min_level: 3\n",
      "        max_level: 7\n",
      "        num_iterations: 3\n",
      "        num_filters: 64\n",
      "      }\n",
      "      conv_hyperparams {\n",
      "        force_use_bias: true\n",
      "        activation: SWISH\n",
      "        regularizer {\n",
      "          l2_regularizer {\n",
      "            weight: 0.00004\n",
      "          }\n",
      "        }\n",
      "        initializer {\n",
      "          truncated_normal_initializer {\n",
      "            stddev: 0.03\n",
      "            mean: 0.0\n",
      "          }\n",
      "        }\n",
      "        batch_norm {\n",
      "          scale: true,\n",
      "          decay: 0.99,\n",
      "          epsilon: 0.001,\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    loss {\n",
      "      classification_loss {\n",
      "        weighted_sigmoid_focal {\n",
      "          alpha: 0.25\n",
      "          gamma: 1.5\n",
      "        }\n",
      "      }\n",
      "      localization_loss {\n",
      "        weighted_smooth_l1 {\n",
      "        }\n",
      "      }\n",
      "      classification_weight: 1.0\n",
      "      localization_weight: 1.0\n",
      "    }\n",
      "    normalize_loss_by_num_matches: true\n",
      "    normalize_loc_loss_by_codesize: true\n",
      "    post_processing {\n",
      "      batch_non_max_suppression {\n",
      "        score_threshold: 1e-8\n",
      "        iou_threshold: 0.5\n",
      "        max_detections_per_class: 100\n",
      "        max_total_detections: 100\n",
      "      }\n",
      "      score_converter: SIGMOID\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "train_config: {\n",
      "  fine_tune_checkpoint: \"/content/models/research/deploy/efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0\"\n",
      "  fine_tune_checkpoint_version: V2\n",
      "  fine_tune_checkpoint_type: \"detection\"\n",
      "  batch_size: 16\n",
      "  sync_replicas: true\n",
      "  startup_delay_steps: 0\n",
      "  replicas_to_aggregate: 8\n",
      "  use_bfloat16: true\n",
      "  num_steps: 50000\n",
      "  data_augmentation_options {\n",
      "    random_horizontal_flip {\n",
      "    }\n",
      "  }\n",
      "  data_augmentation_options {\n",
      "    random_scale_crop_and_pad_to_square {\n",
      "      output_size: 512\n",
      "      scale_min: 0.1\n",
      "      scale_max: 2.0\n",
      "    }\n",
      "  }\n",
      "  optimizer {\n",
      "    momentum_optimizer: {\n",
      "      learning_rate: {\n",
      "        cosine_decay_learning_rate {\n",
      "          learning_rate_base: 8e-2\n",
      "          total_steps: 300000\n",
      "          warmup_learning_rate: .001\n",
      "          warmup_steps: 2500\n",
      "        }\n",
      "      }\n",
      "      momentum_optimizer_value: 0.9\n",
      "    }\n",
      "    use_moving_average: false\n",
      "  }\n",
      "  max_number_of_boxes: 100\n",
      "  unpad_groundtruth_tensors: false\n",
      "}\n",
      "\n",
      "train_input_reader: {\n",
      "  label_map_path: \"/content/Hama-tanaman-berdaun-3/train/Hama_label_map.pbtxt\"\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"/content/Hama-tanaman-berdaun-3/train/Hama.tfrecord\"\n",
      "  }\n",
      "}\n",
      "\n",
      "eval_config: {\n",
      "  metrics_set: \"coco_detection_metrics\"\n",
      "  use_moving_averages: false\n",
      "  batch_size: 16;\n",
      "}\n",
      "\n",
      "eval_input_reader: {\n",
      "  label_map_path: \"/content/Hama-tanaman-berdaun-3/train/Hama_label_map.pbtxt\"\n",
      "  shuffle: false\n",
      "  num_epochs: 1\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"/content/Hama-tanaman-berdaun-3/test/Hama.tfrecord\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%cat /content/models/research/deploy/pipeline_file.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AEFT2EJH6DcX"
   },
   "outputs": [],
   "source": [
    "pipeline_file = '/content/models/research/deploy/pipeline_file.config'\n",
    "model_dir = '/content/training/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v0Uy8NEt6SQZ",
    "outputId": "0ac9ae26-2cfd-42bb-856a-4b3b932d4f46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-13 12:38:57.890194: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-13 12:39:01.606108: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "I1113 12:39:01.607654 138985198654080 mirrored_strategy.py:419] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 50000\n",
      "I1113 12:39:01.630002 138985198654080 config_util.py:552] Maybe overwriting train_steps: 50000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I1113 12:39:01.630190 138985198654080 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "I1113 12:39:01.639820 138985198654080 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I1113 12:39:01.639940 138985198654080 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 64\n",
      "I1113 12:39:01.640011 138985198654080 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 3\n",
      "I1113 12:39:01.647103 138985198654080 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I1113 12:39:01.686544 138985198654080 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I1113 12:39:01.686679 138985198654080 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I1113 12:39:01.785443 138985198654080 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I1113 12:39:01.785616 138985198654080 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I1113 12:39:02.048085 138985198654080 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I1113 12:39:02.048257 138985198654080 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I1113 12:39:02.305247 138985198654080 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I1113 12:39:02.305438 138985198654080 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I1113 12:39:02.664327 138985198654080 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I1113 12:39:02.664537 138985198654080 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I1113 12:39:03.184014 138985198654080 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I1113 12:39:03.184215 138985198654080 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I1113 12:39:03.905525 138985198654080 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I1113 12:39:03.905711 138985198654080 efficientnet_model.py:143] round_filter input=320 output=320\n",
      "I1113 12:39:04.092743 138985198654080 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
      "I1113 12:39:04.207554 138985198654080 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W1113 12:39:04.285229 138985198654080 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['/content/Hama-tanaman-berdaun-3/train/Hama.tfrecord']\n",
      "I1113 12:39:04.298735 138985198654080 dataset_builder.py:162] Reading unweighted datasets: ['/content/Hama-tanaman-berdaun-3/train/Hama.tfrecord']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['/content/Hama-tanaman-berdaun-3/train/Hama.tfrecord']\n",
      "I1113 12:39:04.298957 138985198654080 dataset_builder.py:79] Reading record datasets for input file: ['/content/Hama-tanaman-berdaun-3/train/Hama.tfrecord']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I1113 12:39:04.299037 138985198654080 dataset_builder.py:80] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W1113 12:39:04.299103 138985198654080 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W1113 12:39:04.310164 138985198654080 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W1113 12:39:04.344624 138985198654080 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W1113 12:39:11.731650 138985198654080 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W1113 12:39:16.755172 138985198654080 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "2024-11-13 12:39:20.588338: W tensorflow/core/framework/dataset.cc:956] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n",
      "I1113 12:39:28.237442 138980712511040 api.py:460] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\n",
      "I1113 12:39:41.955591 138980712511040 api.py:460] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\n",
      "2024-11-13 12:39:54.632960: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 402653184 exceeds 10% of free system memory.\n",
      "2024-11-13 12:39:54.915269: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 402653184 exceeds 10% of free system memory.\n",
      "2024-11-13 12:40:03.785017: W tensorflow/core/framework/dataset.cc:956] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W1113 12:40:05.162096 138981017646656 deprecation.py:569] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "I1113 12:40:07.268173 138981017646656 api.py:460] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['top_conv2d/kernel:0', 'top_bn/gamma:0', 'top_bn/beta:0', 'logits/kernel:0', 'logits/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "W1113 12:40:16.452314 138981017646656 utils.py:82] Gradients do not exist for variables ['top_conv2d/kernel:0', 'top_bn/gamma:0', 'top_bn/beta:0', 'logits/kernel:0', 'logits/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "I1113 12:40:21.302041 138981017646656 api.py:460] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['top_conv2d/kernel:0', 'top_bn/gamma:0', 'top_bn/beta:0', 'logits/kernel:0', 'logits/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "W1113 12:40:29.959605 138981017646656 utils.py:82] Gradients do not exist for variables ['top_conv2d/kernel:0', 'top_bn/gamma:0', 'top_bn/beta:0', 'logits/kernel:0', 'logits/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "I1113 12:40:34.510943 138981017646656 api.py:460] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['top_conv2d/kernel:0', 'top_bn/gamma:0', 'top_bn/beta:0', 'logits/kernel:0', 'logits/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "W1113 12:40:43.016043 138981017646656 utils.py:82] Gradients do not exist for variables ['top_conv2d/kernel:0', 'top_bn/gamma:0', 'top_bn/beta:0', 'logits/kernel:0', 'logits/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "I1113 12:40:47.776643 138981017646656 api.py:460] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['top_conv2d/kernel:0', 'top_bn/gamma:0', 'top_bn/beta:0', 'logits/kernel:0', 'logits/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "W1113 12:40:56.988247 138981017646656 utils.py:82] Gradients do not exist for variables ['top_conv2d/kernel:0', 'top_bn/gamma:0', 'top_bn/beta:0', 'logits/kernel:0', 'logits/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "2024-11-13 12:41:19.973419: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 402653184 exceeds 10% of free system memory.\n",
      "2024-11-13 12:41:20.535384: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 402653184 exceeds 10% of free system memory.\n",
      "2024-11-13 12:41:21.174412: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 402653184 exceeds 10% of free system memory.\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
    "    --pipeline_config_path={pipeline_file} \\\n",
    "    --model_dir={model_dir} \\\n",
    "    --alsologtostderr \\\n",
    "    --num_train_steps={num_steps} \\\n",
    "    --sample_1_of_n_eval_examples=1 \\\n",
    "    --num_eval_steps={num_eval_steps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUny3LBoKHx4"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir '/content/training/train'"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
